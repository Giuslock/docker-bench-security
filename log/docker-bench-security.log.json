{
  "dockerbenchsecurity": "1.3.6",
  "start": 1633425085,
  "tests": [
    {
      "id": "4",
      "desc": "Container Images and Build File",
      "results": [
        {
          "id": "4.1",
          "desc": "Ensure that a user for the container has been created",
          "result": "WARN",
          "details": "running as root:  jolly_swartz",
          "items": [
            "jolly_swartz"
          ],
          "remediation": "You should ensure that the Dockerfile for each container image contains the information: USER <username or ID>. If there is no specific user created in the container base image, then make use of the useradd command to add a specific user before the USER instruction in the Dockerfile.",
          "remediation-impact": "Running as a non-root user can present challenges where you wish to bind mount volumes from the underlying host. In this case, care should be taken to ensure that the user running the contained process can read and write to the bound directory, according to their requirements."
        },
        {
          "id": "4.2",
          "desc": "Ensure that containers use only trusted base images",
          "result": "NOTE",
          "remediation": "Configure and use Docker Content trust. View the history of each Docker image to evaluate its risk, dependent on the sensitivity of the application you wish to deploy using it. Scan Docker images for vulnerabilities at regular intervals. Use the commands docker history <imageName> and docker image scan <imageName>",
          "remediation-impact": "None."
        },
        {
          "id": "4.3",
          "desc": "Ensure that unnecessary packages are not installed in the container",
          "result": "NOTE",
          "remediation": "You should not install anything within the container that is not required. You should consider using a minimal base image if you can. Some of the options available include BusyBox and Alpine. Not only can this trim your image size considerably, but there would also be fewer pieces of software which could contain vectors for attack. To review the list of the packages installed depending on which distro your image is based the commands are docker exec -i <container_id>  dpkg -l for ubuntu based, docker exec -i <container_id>  rpm -qa for RHEL, CentOS and Fedora - based containers, docker exec -i <container_id>  apk info -vv | sort for Alpine-based containers.",
          "remediation-impact": "None."
        },
        {
          "id": "4.4",
          "desc": "Ensure images are scanned and rebuilt to include security patches",
          "result": "NOTE",
          "remediation": "Images should be re-built ensuring that the latest version of the base images are used, to keep the operating system patch level at an appropriate level. Once the images have been re-built, containers should be re-started making use of the updated images.",
          "remediation-impact": "None."
        },
        {
          "id": "4.5",
          "desc": "Ensure Content trust for Docker is Enabled",
          "result": "WARN",
          "remediation": "Add DOCKER_CONTENT_TRUST variable to the /etc/environment file using command echo DOCKER_CONTENT_TRUST=1 | sudo tee -a /etc/environment.",
          "remediation-impact": "This prevents users from working with tagged images unless they contain a signature."
        },
        {
          "id": "4.6",
          "desc": "Ensure that HEALTHCHECK instructions have been added to container images",
          "result": "WARN",
          "details": "Images w/o HEALTHCHECK:  558db7397769 [php:7.4-fpm-alpine3.14]",
          "items": [
            "558db7397769","[php:7.4-fpm-alpine3.14]"
          ],
          "remediation": "An important security control is that of availability. Adding the HEALTHCHECK instruction to your container image ensures that the Docker engine periodically checks the running container instances against that instruction to ensure that containers are still operational. Based on the results of the health check, the Docker engine could terminate containers which are not responding correctly, and instantiate new ones.",
          "remediation-impact": "None."
        },
        {
          "id": "4.7",
          "desc": "Ensure update instructions are not used alone in the Dockerfile",
          "result": "PASS"
        },
        {
          "id": "4.8",
          "desc": "Ensure setuid and setgid permissions are removed",
          "result": "NOTE",
          "remediation": "You should allow setuid and setgid permissions only on executables which require them. You could remove these permissions at build time by adding the following command in your Dockerfile, preferably towards the end of the Dockerfile. ",
          "remediation-impact": "The above command would break all executables that depend on setuid or setgid permissions including legitimate ones. You should therefore be careful to modify the command to suit your requirements so that it does not reduce the permissions of legitimate programs excessively. Because of this, you should exercise a degree of caution and examine all processes carefully before making this type of modification in order to avoid outages."
        },
        {
          "id": "4.9",
          "desc": "Ensure that COPY is used instead of ADD in Dockerfiles",
          "result": "PASS"
        },
        {
          "id": "4.10",
          "desc": "Ensure secrets are not stored in Dockerfiles",
          "result": "NOTE",
          "remediation": "Do not store any kind of secrets within Dockerfiles. Where secrets are required during the build process, make use of a secrets management tool, such as the buildkit builder included with Docker.",
          "remediation-impact": "A proper secrets management process will be required for Docker image building."
        },
        {
          "id": "4.11",
          "desc": "Ensure only verified packages are are installed",
          "result": "NOTE",
          "remediation": "You should use a secure package distribution mechanism of your choice to ensure the authenticity of software packages.",
          "remediation-impact": "None."
        }
      ]
    },
    {
      "id": "5",
      "desc": "Container Runtime",
      "results": [
        {
          "id": "5.1",
          "desc": "Ensure that, if applicable, an AppArmor Profile is enabled",
          "result": "PASS"
        },
        {
          "id": "5.2",
          "desc": "Ensure that, if applicable, SELinux security options are set",
          "result": "WARN",
          "details": "Containers with no SecurityOptions:  jolly_swartz",
          "items": [
            "jolly_swartz"
          ],
          "remediation": "Set the SELinux State. Set the SELinux Policy. Create or import a SELinux policy template for Docker containers. Start Docker in daemon mode with SELinux enabled. Start your Docker container using the security options.You should run your container with the option: --security-opt label=level:YourLabel",
          "remediation-impact": "Any restrictions defined in the SELinux policy will be applied to your containers. It should be noted that if your SELinux policy is misconfigured, this may have an impact on the correct operation of the affected containers."
        },
        {
          "id": "5.3",
          "desc": "Ensure that Linux kernel capabilities are restricted within containers",
          "result": "PASS"
        },
        {
          "id": "5.4",
          "desc": "Ensure that privileged containers are not used",
          "result": "PASS"
        },
        {
          "id": "5.5",
          "desc": "Ensure sensitive host system directories are not mounted on containers",
          "result": "PASS"
        },
        {
          "id": "5.6",
          "desc": "Ensure sshd is not run within containers",
          "result": "PASS"
        },
        {
          "id": "5.7",
          "desc": "Ensure privileged ports are not mapped within containers",
          "result": "PASS"
        },
        {
          "id": "5.8",
          "desc": "Ensure that only needed ports are open on the container",
          "result": "NOTE",
          "remediation": "The dockerfile for a container image defines the ports which are opened by default on a container instance. The list of ports are relevant to the application you are running within the container and should only be open if they are needed. You should ensure that the Dockerfile for each container image only exposes needed ports.",
          "remediation-impact": "None."
        },
        {
          "id": "5.9",
          "desc": "Ensure that the host's network namespace is not shared",
          "result": "PASS"
        },
        {
          "id": "5.10",
          "desc": "Ensure that the memory usage for containers is limited",
          "result": "WARN",
          "details": "Container running without memory restrictions:  jolly_swartz",
          "items": [
            "jolly_swartz"
          ],
          "remediation": "By default a container can use all of the memory on the host. You can use memory limit mechanisms to prevent a denial of service occurring where one container consumes all of
the hostâ€™s resources and other containers on the same host are therefore not able to function. Having no limit on memory usage can lead to issues where one container can easily make the whole system unstable and as a result unusable.You should run the container with only as much memory as it requires by using the --memory argument.",
          "remediation-impact": "If correct memory limits are not set on each container, one process can expand its usage and cause other containers to run out of resources."
        },
        {
          "id": "5.11",
          "desc": "Ensure that CPU priority is set appropriately on containers",
          "result": "WARN",
          "details": "Containers running without CPU restrictions:  jolly_swartz jolly_swartz",
          "items": [
            "jolly_swartz","jolly_swartz"
          ],
          "remediation": "By default, CPU time is divided between containers equally. If you wish to control available CPU resources amongst container instances, you can use the CPU sharing feature. CPU sharing allows you to prioritize one container over others and prevents lower priority
containers from absorbing CPU resources which may be required by other processes. This
ensures that high priority containers are able to claim the CPU runtime they require.You should manage the CPU runtime between your containers dependent on their priority within your organization. To do so start the container using the --cpu-shares argument.",
          "remediation-impact": "If you do not correctly assign CPU thresholds, the container process may run out of resources and become unresponsive. If CPU resources on the host are not constrainted, CPU shares do not place any restrictions on individual resources."
        },
        {
          "id": "5.12",
          "desc": "Ensure that the container's root filesystem is mounted as read only",
          "result": "WARN",
          "details": "Containers running with root FS mounted R/W:  jolly_swartz",
          "items": [
            "jolly_swartz"
          ],
          "remediation": "The container's root filesystem should be treated as a 'golden image' by using Docker run's --read-only option. This prevents any writes to the container's root filesystem at
container runtime and enforces the principle of immutable infrastructure.Enabling this option forces containers at runtime to explicitly define their data writing
strategy to persist or not persist their data.
This also reduces security attack vectors since the container instance's filesystem cannot
be tampered with or written to unless it has explicit read-write permissions on its
filesystem folder and directories. You should add a --read-only flag at a container's runtime to enforce the container's root filesystem being mounted as read only.",
          "remediation-impact": "Enabling --read-only at container runtime may break some container OS packages if a data writing strategy is not defined. You should define what the container's data should and should not persist at runtime in order to decide which strategy to use."
        },
        {
          "id": "5.13",
          "desc": "Ensure that incoming container traffic is bound to a specific host interface",
          "result": "PASS"
        },
        {
          "id": "5.14",
          "desc": "Ensure that the 'on-failure' container restart policy is set to '5'",
          "result": "WARN",
          "details": "Containers with MaximumRetryCount not set to 5:  jolly_swartz",
          "items": [
            "jolly_swartz"
          ],
          "remediation": "By using the --restart flag in the docker run command you can specify a restart policy for
how a container should or should not be restarted on exit.If you indefinitely keep trying to start the container, it could possibly lead to a denial of
service on the host. It could be an easy way to do a distributed denial of service attack
especially if you have many containers on the same host. Additionally, ignoring the exit
status of the container and always attempting to restart the container, leads to non-
investigation of the root cause behind containers getting terminated. If a container gets
terminated, you should investigate on the reason behind it instead of just attempting to
restart it indefinitely. You should use the on-failure restart policy to limit the number of
container restarts to a maximum of 5 attempts.If you wish a container to be automatically restarted, a sample command is docker run --detach --restart=on-failure:5 nginx",
          "remediation-impact": "If this option is set, a container will only attempt to restart itself 5 times."
        },
        {
          "id": "5.15",
          "desc": "Ensure that the host's process namespace is not shared",
          "result": "PASS"
        },
        {
          "id": "5.16",
          "desc": "Ensure that the host's IPC namespace is not shared",
          "result": "PASS"
        },
        {
          "id": "5.17",
          "desc": "Ensure that host devices are not directly exposed to containers",
          "result": "PASS"
        },
        {
          "id": "5.18",
          "desc": "Ensure that the default ulimit is overwritten at runtime if needed",
          "result": "INFO",
          "details": "Containers with no default ulimit override:  jolly_swartz",
          "items": [
            "jolly_swartz"
          ],
          "remediation": "ulimit provides control over the resources available to the shell and to processes started by it. Setting system resource limits in a prudent fashion, protects against denial of service conditions. On occasion, legitimate users and processes can accidentally overuse system resources and cause systems be degraded or even unresponsive.
The default ulimit set at the Docker daemon level should be honored. If the default ulimit
settings are not appropriate for a particular container instance, you may override them as
an exception, but this should not be done routinely. If many of your container instances are
exceeding your ulimit settings, you should consider changing the default settings to
something that is more appropriate for your needs.You should only override the default ulimit settings if needed in a specific case.",
          "remediation-impact": "If ulimits are not set correctly, overutilization by individual containers could make the host system unusable."
        },
        {
          "id": "5.19",
          "desc": "A shared mount is replicated at all mounts and changes made at any mount point are
propagated to all other mount points.
Mounting a volume in shared mode does not restrict any other container from mounting
and making changes to that volume.
As this is likely not a desirable option from a security standpoint, this feature should not be
used unless explicitly required.Ensure mount propagation mode is not set to shared",
          "result": "PASS"
        },
        {
          "id": "5.20",
          "desc": "Ensure that the host's UTS namespace is not shared ",
          "result": "PASS"
        },
        {
          "id": "5.21",
          "desc": "Ensurethe default seccomp profile is not Disabled ",
          "result": "PASS"
        },
        {
          "id": "5.22",
          "desc": "Ensure that docker exec commands are not used with the privileged option ",
          "result": "NOTE",
          "remediation": "Using the --privileged option in docker exec commands gives extended Linux
capabilities to the command. This could potentially be an insecure practice, particularly
when you are running containers with reduced capabilities or with enhanced restrictions.You should not use the --privileged option in docker exec commands.",
          "remediation-impact": "If you need enhanced capabilities within a container, then run it with all the permissions it requires. These should be specified individually."
        },
        {
          "id": "5.23",
          "desc": "Ensure that docker exec commands are not used with the user=root option ",
          "result": "NOTE",
          "remediation": "Using the --user=root option in a docker exec command, executes it within the container
as the root user. This could potentially be insecure, particularly when you are running
containers with reduced capabilities or enhanced restrictions.
For example, if your container is running as a tomcat user (or any other non-root user), it
would be possible to run a command through docker exec as root with the --user=root
option. This could potentially be dangerous.You should not use the --user=root option in docker exec commands.",
          "remediation-impact": "None."
        },
        {
          "id": "5.24",
          "desc": "Ensure that cgroup usage is confirmed ",
          "result": "PASS"
        },
        {
          "id": "5.25",
          "desc": "Ensure that the container is restricted from acquiring additional privileges ",
          "result": "WARN",
          "details": "Containers without restricted privileges:  jolly_swartz",
          "items": [
            "jolly_swartz"
          ],
          "remediation": "A process can set the no_new_priv bit in the kernel and this persists across forks, clones
and execve. The no_new_priv bit ensures that the process and its child processes do not
gain any additional privileges via suid or sgid bits. This reduces the danger associated with
many operations because the possibility of subverting privileged binaries is lessened.You should start your container with the options: docker run --rm -it --security-opt=no-new-privileges ubuntu bash",
          "remediation-impact": "The no_new_priv option prevents LSMs like SELinux from allowing processes to acquire new privileges."
        },
        {
          "id": "5.26",
          "desc": "Ensure that container health is checked at runtime ",
          "result": "WARN",
          "details": "Containers without health check:  jolly_swartz",
          "items": [
            "jolly_swartz"
          ],
          "remediation": "If the container image you are using does not have a pre-defined HEALTHCHECK instruction,
use the --health-cmd parameter to check container health at runtime.
Based on the reported health status, remedial actions can be taken if necessary.You should run the container using the --health-cmd parameter.",
          "remediation-impact": "None."
        },
        {
          "id": "5.27",
          "desc": "Ensure that Docker commands always make use of the latest version of their image ",
          "result": "INFO",
          "remediation": "Multiple Docker commands such as docker pull , docker run etc. are known to have an
issue where by default, they extract the local copy of the image, if present, even though
there is an updated version of the image with the same tag in the upstream repository. This
could lead to using older images containing known vulnerabilites.You should use proper version pinning mechanisms (the <latest> tag which is assigned by default is still vulnerable to caching attacks) to avoid extracting cached older versions. Version pinning mechanisms should be used for base images, packages, and entire images. You can customize version pinning rules according to your requirements.",
          "remediation-impact": "None."
        },
        {
          "id": "5.28",
          "desc": "Ensure that the PIDs cgroup limit is used",
          "result": "WARN",
          "details": "Containers without PIDs cgroup limit:  jolly_swartz",
          "items": [
            "jolly_swartz"
          ],
          "remediation": "Attackers could launch a fork bomb with a single command inside the container. This fork
bomb could crash the entire system and would require a restart of the host to make the
system functional again. Using the PIDs cgroup parameter --pids-limit would prevent
this kind of attack by restricting the number of forks that can happen inside a container
within a specified time frame.Use --pids-limit flag with an appropriate value when launching the container.",
          "remediation-impact": "Set the PIDs limit value as appropriate. Incorrect values might leave containers unusable."
        },
        {
          "id": "5.29",
          "desc": "Ensure that Docker's default bridge docker0 is not used ",
          "result": "INFO",
          "details": "Containers using docker0 network:  1485adc5998b1d64fd8ae7978f284a7d95c3caccd4c3ff33dd750dc0631996db:jolly_swartz",
          "items": [
            "1485adc5998b1d64fd8ae7978f284a7d95c3caccd4c3ff33dd750dc0631996db:jolly_swartz"
          ],
          "remediation": "Docker connects virtual interfaces created in bridge mode to a common bridge called
docker0 . This default networking model is vulnerable to ARP spoofing and MAC flooding
attacks as there is no filtering applied to it.You should follow the Docker documentation and set up a user-defined network. All the containers should be run in this network.",
          "remediation-impact": "User-defined networks need to be configured and managed in line with organizational security policy."
        },
        {
          "id": "5.30",
          "desc": "User namespaces ensure that a root process inside the container will be mapped to a non-
root process outside the container. Sharing the user namespaces of the host with the
container does not therefore isolate users on the host from users in the containers.Ensure that the host's user namespaces are not shared",
          "result": "PASS"
        },
        {
          "id": "5.31",
          "desc": "If the Docker socket is mounted inside a container it could allow processes running within
the container to execute Docker commands which would effectively allow for full control of
the host.Ensure that the Docker socket is not mounted inside any containers",
          "result": "PASS"
        }
      ]
    }
  ],
  "checks": 42,
  "score": 5,
  "end": 1633425087
}